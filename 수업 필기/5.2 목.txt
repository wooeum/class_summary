모델은 데이터에 맞춰나온게 아니라서 fit을 통해 데이터에 맞게 학습시켜야됨.
너무 fit했다 -> overfitting했다 => train set에만 너무 맞춰져있다
오버피팅 - 복잡도가 높다
언더피팅 - 복잡도가 낮다

랜덤 포레스트는 결정나무 여러개를 묶어서 결정하는것. (ex. 결정나무 100개를 묶은 것)
모델의 복잡도는 모델을 바꾸거나 규제 파라미터(max_depth)를 사용해야됨

성능이 같다면 복잡도가 더 낮은 모델을 사용 & train과 valid set의 성능이 비슷한 것 사용

하이퍼 파라미터 튜닝 방법 두가지
- grid~
- randomi~

> 파이프라인 
데이터를 보내서 계속적으로 처리를 해주겠다
함수와 비슷한 개념

!! 04에서 스케일러부분 복습하기 !!

왜 transform을 할까 
다 fit하는게 목적이지만 자기가 학습한것을 다음으로 넘겨줘야되니까 변환해서 넘겨준다. 목적은 fit하는 것. 
< 각 단계에서 필요한 형태가 있다 >

test단계에서는 이미 fit은 끝났으므로 transform만 하면 된다

파이프라인을 안쓴다면 직접 스케일러에 넣어서 학습시키고 변환하는 과정을 반복


steps 에서 리스트로 해주는 이유는 순서가 중요하기 때문이다.
각 단계의 이름과 함수를 넣어주는데 형태가 dictionary이지만 dictionary는 먼저 들어왔다해도 먼저 나오지 않기떄문에 순서를 보장해주지 못하므로 리스트 형태인 OrderedDict를 사용한다

전처리는 여러번해줘도 되지만 모델은 하나만 들어와야됨. (추정기는 마지막에 하나만)

2개로 줄인이유 => 시각화를 하려면 2개의 특성만 남아야하므로

gridSearch는 모델의 최적의 하이퍼파라미터를 찾는것
하지만 pipeline이 모델은 아니다. 파이프라인은 3개의 모델을 가지고있어서 셋 모두의 파라미터를 찾겠다는건데 세 하이퍼파라미터가 각각 어떤 모델의 하이퍼파라미터인지를 모른다.  c가 누구껀지, gamma가 누구껀지 모르니까 모델에 넣을 수 없음. 하나일땐 모델이 하나이므로 지정해줄 수 있었다. 그러므로 파라미터 앞에서 이름을 넣어줘야된다.
구분자 __ => 왜? __가 들어간 하이퍼파라미터는 없으므로 구분을 지어줄 수 있기때문에

column transformer - 전처리기
=> 컬럼별로 다른 전처리를 하겠다

스케일링 방법이 다를 수 있고, 같은 수치형이라도 다른 방법으로 전처리할 수 있다. 
컬럼별로 다른 전처리를 해주고싶어서 만든게 column transformer
어떻게 쓰냐? 

