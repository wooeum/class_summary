오차를 계산하는 것 => 손실함수 => 의 결과값중 최솟값을 만드는 파라미터들을 찾는다.

linear regression은 손실함수로 MSE사용 (y-y^)**2

w절댓값이나 제곱한 값을 통해 규제를 할 수 있고 이를 규제항이라고 부른다
Ridge - w 절댓값의 제곱
Lasso - w 절댓값
ElasticNet(엘라스틱넷) - 위 두개를 절충한 모델

리니어 리그레션하면 수치값이 나오는데 이를 이진 분류 문제로 바꾼게 로지스틱 회귀이다.

로지스틱 회귀는 손실함수로 로그로스를 사용한다
이진분류일때의 계산 공식은 따로 있음

로지스틱 회귀는 경사하강법을 통해 최적화

최적화 함수가 없을때 => 경사하강법 사용