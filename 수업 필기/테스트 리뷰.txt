여러 모델을 결합해서 만든 머신러닝 모델을 앙상블이라고 한다

Q. 딥러닝 모델과 다른 머신러닝 알고리즘의 가장 큰 차이점은?
딥러닝은 feature extractor가 모델안에 포함되어 학습된다. 전통적인 머신러닝은 사람이 feature extractor를 정의한다


Q. __call__() 함수에 대해서
m = XXXModel()
pred = m(input) => 이것은 call함수를 호출하지만 이것은 nn,Module에 정의되어있고 공통적인 것들을 담아두었다. call에서 forward()를 호출해 모델마다 다르게 정의된 것들을 호출한다.


Q.모델 학습 순서
모델을 이용해 추정
loss 계산
loss를 이용해서 gradient를 계산
모델 파라미터들 업데이트


Q. dataset과 dataloader
Dataset - 학습 데이터(x,y)를 하나씩 load하는 것이 목적. raw_data -> dataset
DataLoader - 학습데이터를 batch단위로 묶어서 모델에 제공하는 것이 목적. DL -> model
raw_data -> Dataset -> DataLoader -> 모델


Q13. 입력분포를 균일하게 
batch normalization을 하는 이유. 각 입력마다 평균과 표준편차를 조절해줌
레이어가 깊어질때 모델 사이에서 batch norm하는게 더 효과적임


Q. 모델의 성능을 올리기 위해 미리 학습된 모델의 구조와 파라미터를 이용해서 새로운 모델을 정의하는 방식은 전이학습. Transfer learning이다.


Q. LSTM, GRU중 어떤것을 사용할지 고려할때. 두 모델은 비슷하므로 자기가 잘쓸 수 있는거를 사용함

nn.Enbedding -> 100 => 컬럼을 100개 만들어라. 모델을 100개의 숫자로 표현해라

with ZipFile(zipfile) as zf:
	zf.extractall(target_path)


